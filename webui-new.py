import json
import os
import sys
import threading
import time
import re

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# --- å…¨å±€è·¯å¾„å’Œé…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, "indextts")) # å‡è®¾indexttsåœ¨å­ç›®å½•

RULES_DIR = os.path.join(current_dir, "pinyin_rules") # è§„åˆ™å­˜å‚¨ç›®å½•
os.makedirs(RULES_DIR, exist_ok=True) # åˆ›å»ºè§„åˆ™ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

import argparse
parser = argparse.ArgumentParser(description="IndexTTS WebUI")
parser.add_argument("--verbose", action="store_true", default=False, help="Enable verbose mode")
parser.add_argument("--port", type=int, default=7860, help="Port to run the web UI on")
parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to run the web UI on")
parser.add_argument("--model_dir", type=str, default="checkpoints", help="Model checkpoints directory")
cmd_args = parser.parse_args()

# --- æ¨¡å‹æ–‡ä»¶æ£€æŸ¥ ---
model_dir_abs = os.path.join(current_dir, cmd_args.model_dir) # ç¡®ä¿model_diræ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºè„šæœ¬
if not os.path.exists(model_dir_abs):
    print(f"Model directory {model_dir_abs} does not exist. Please download the model first.")
    sys.exit(1)

required_model_files = ["bigvgan_generator.pth", "bpe.model", "gpt.pth", "config.yaml"]
for file_name in required_model_files:
    file_path = os.path.join(model_dir_abs, file_name)
    if not os.path.exists(file_path):
        print(f"Required model file {file_path} does not exist. Please download it.")
        sys.exit(1)

import gradio as gr

from indextts.infer import IndexTTS
from tools.i18n.i18n import I18nAuto # å‡è®¾è¿™ä¸ªè·¯å¾„æ˜¯æ­£ç¡®çš„

i18n = I18nAuto(language="zh_CN") # æ ¹æ®éœ€è¦è°ƒæ•´è¯­è¨€
MODE = 'local' # å‡è®¾
tts = IndexTTS(model_dir=model_dir_abs, cfg_path=os.path.join(model_dir_abs, "config.yaml"))

os.makedirs(os.path.join(current_dir, "outputs/tasks"), exist_ok=True)
os.makedirs(os.path.join(current_dir, "prompts"), exist_ok=True)

# --- åŠ è½½ç¤ºä¾‹ç”¨ä¾‹ ---
example_cases_path = os.path.join(current_dir, "tests/cases.jsonl")
example_cases = []
if os.path.exists(example_cases_path):
    with open(example_cases_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                example = json.loads(line)
                prompt_audio_filename = example.get("prompt_audio", "sample_prompt.wav")
                # ç¡®ä¿å‚è€ƒéŸ³é¢‘è·¯å¾„ç›¸å¯¹äº 'tests' ç›®å½•æˆ–è„šæœ¬ç›®å½•
                prompt_audio_path = os.path.join(current_dir, "tests", prompt_audio_filename)
                if not os.path.exists(prompt_audio_path):
                     # å°è¯•ç›´æ¥åœ¨ prompts ç›®å½•æˆ– model_dir/tests æŸ¥æ‰¾ (æ ¹æ®ä½ çš„å®é™…ç»“æ„)
                    alt_path1 = os.path.join(current_dir, "prompts", prompt_audio_filename)
                    if os.path.exists(alt_path1):
                        prompt_audio_path = alt_path1
                    else:
                        print(f"Warning: Example prompt audio not found: {prompt_audio_path} (and alternatives)")
                
                example_cases.append([
                    prompt_audio_path,
                    example.get("text"),
                    ["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"][example.get("infer_mode", 0)]
                ])
            except json.JSONDecodeError as e:
                print(f"Error decoding JSON from cases.jsonl: {e} in line: {line}")
            except Exception as e:
                print(f"Error processing example case: {e}")
else:
    print(f"Warning: Example cases file not found: {example_cases_path}")

# --- è§„åˆ™ç®¡ç†è¾…åŠ©å‡½æ•° ---
def get_saved_rules_list():
    if not os.path.exists(RULES_DIR):
        return []
    try:
        rules_files = [f for f in os.listdir(RULES_DIR) if f.endswith(".json")]
        return sorted([os.path.splitext(f)[0] for f in rules_files])
    except Exception as e:
        print(f"Error listing rules directory {RULES_DIR}: {e}")
        return []

def save_rules_to_file(rules_name, rules_content_str):
    if not rules_name.strip():
        gr.Warning("è§„åˆ™åç§°ä¸èƒ½ä¸ºç©ºï¼")
        return False, get_saved_rules_list(), None
    
    safe_rules_name = "".join(c for c in rules_name if c.isalnum() or c in (' ', '_', '-')).strip()
    if not safe_rules_name:
        gr.Warning("è§„åˆ™åç§°åŒ…å«æ— æ•ˆå­—ç¬¦æˆ–åç§°å¤„ç†åä¸ºç©ºï¼")
        return False, get_saved_rules_list(), None

    filepath = os.path.join(RULES_DIR, f"{safe_rules_name}.json")
    try:
        rules_content_to_save = rules_content_str if rules_content_str is not None else ""
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump({"content": rules_content_to_save}, f, ensure_ascii=False, indent=2)
        gr.Info(f"è§„åˆ™ '{safe_rules_name}' å·²ä¿å­˜ï¼")
        return True, get_saved_rules_list(), safe_rules_name
    except Exception as e:
        gr.Error(f"ä¿å­˜è§„åˆ™ '{safe_rules_name}' å¤±è´¥: {e}")
        return False, get_saved_rules_list(), None

def load_rules_from_file(rules_name):
    if not rules_name:
        return "" 
    filepath = os.path.join(RULES_DIR, f"{rules_name}.json")
    if os.path.exists(filepath):
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("content", "") 
        except Exception as e:
            gr.Error(f"åŠ è½½è§„åˆ™ '{rules_name}' å¤±è´¥: {e}")
            return "" 
    else:
        return "" 

def delete_rules_file(rules_name):
    if not rules_name: # Should not happen if called from dropdown selection
        gr.Warning("æ²¡æœ‰é€‰æ‹©è¦åˆ é™¤çš„è§„åˆ™ã€‚")
        return get_saved_rules_list()
        
    filepath = os.path.join(RULES_DIR, f"{rules_name}.json")
    if os.path.exists(filepath):
        try:
            os.remove(filepath)
            gr.Info(f"è§„åˆ™ '{rules_name}' å·²åˆ é™¤ï¼")
        except Exception as e:
            gr.Error(f"åˆ é™¤è§„åˆ™ '{rules_name}' å¤±è´¥: {e}")
    else:
        gr.Warning(f"è§„åˆ™æ–‡ä»¶ '{rules_name}.json' æœªæ‰¾åˆ°ï¼Œæ— æ³•åˆ é™¤ã€‚")
    return get_saved_rules_list()

# --- æ‹¼éŸ³/æ–‡æœ¬æ›¿æ¢æ ¸å¿ƒé€»è¾‘ ---
def parse_pinyin_input(pinyin_input_str):
    modifications = {}
    if not pinyin_input_str or not pinyin_input_str.strip():
        return modifications
    pinyin_input_str = pinyin_input_str.strip()
    pairs = re.split(r'\s*,\s*', pinyin_input_str)
    for pair in pairs:
        if not pair.strip():
            continue
        parts = re.split(r'\s*:\s*', pair.strip(), 1) 
        if len(parts) == 2:
            original_phrase, replacement_val = parts
            if original_phrase.strip() and replacement_val.strip():
                 modifications[original_phrase.strip()] = replacement_val.strip()
    return modifications

def process_pinyin_text(original_text, pinyin_modifications):
    if not pinyin_modifications:
        return original_text
    result_text = original_text
    sorted_keys = sorted(pinyin_modifications.keys(), key=len, reverse=True)
    for key in sorted_keys:
        replacement = pinyin_modifications[key]
        if key in result_text:
            result_text = result_text.replace(key, replacement)
    return result_text

def validate_pinyin(pinyin_token):
    if not pinyin_token:
        return False
    return bool(re.fullmatch(r'^[a-zA-Z]+[1-4]$', pinyin_token))

def preview_pinyin_changes(original_text, pinyin_input_str):
    if not original_text:
        return "è¯·å…ˆè¾“å…¥åŸå§‹æ–‡æœ¬"
    
    pinyin_modifications = parse_pinyin_input(pinyin_input_str)
    
    if not pinyin_modifications and pinyin_input_str.strip():
        return f"æ— æ³•è§£ææ‹¼éŸ³/æ›¿æ¢è¾“å…¥: \"{pinyin_input_str}\"\nè¯·ä½¿ç”¨æ ¼å¼å¦‚ åŸæ–‡:æ›¿æ¢ä¸² (ä¾‹å¦‚: å§:wo4, æˆ‘åƒçš„:æˆ‘åƒde4)"

    if not pinyin_modifications:
        return original_text

    invalid_rules_messages = []
    valid_modifications_for_preview = {}
    for key, value in pinyin_modifications.items():
        if not key: continue 
        if len(key) == 1:
            if validate_pinyin(value):
                valid_modifications_for_preview[key] = value
            else:
                invalid_rules_messages.append(f"å•å­—'{key}'çš„æ‹¼éŸ³'{value}'æ ¼å¼é”™è¯¯ (åº”ä¸º å­—æ¯+1-4å£°è°ƒ)")
        else:
            valid_modifications_for_preview[key] = value
    
    processed_text = process_pinyin_text(original_text, valid_modifications_for_preview)
    
    if invalid_rules_messages:
        error_message_intro = f"ä»¥ä¸‹æ‹¼éŸ³/æ›¿æ¢è§„åˆ™å­˜åœ¨é—®é¢˜:\n- "
        error_message_details = "\n- ".join(invalid_rules_messages)
        error_message_outro = f"\n\né¢„è§ˆ (å·²åº”ç”¨æœ‰æ•ˆè§„åˆ™): {processed_text}"
        return error_message_intro + error_message_details + error_message_outro
    
    return processed_text

# --- TTS ç”Ÿæˆå‡½æ•° ---
def gen_single(prompt, text, pinyin_input_str, infer_mode, max_text_tokens_per_sentence=120, sentences_bucket_max_size=4,
               *args, progress=gr.Progress()):
    if not prompt:
        gr.Warning("é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ æˆ–å½•åˆ¶ä¸€ä¸ªå‚è€ƒéŸ³é¢‘ï¼Œç„¶åå†ç‚¹å‡»ç”Ÿæˆï¼")
        return gr.update(value=None, visible=True) 

    output_audio_path = os.path.join(current_dir, "outputs", f"spk_{int(time.time())}.wav")

    pinyin_modifications_parsed = parse_pinyin_input(pinyin_input_str)
    final_modifications_for_tts = {}
    for key, value in pinyin_modifications_parsed.items():
        if len(key) == 1:
            if validate_pinyin(value):
                final_modifications_for_tts[key] = value
        else:
            final_modifications_for_tts[key] = value
    processed_text = process_pinyin_text(text, final_modifications_for_tts)
    
    tts.gr_progress = progress
    do_sample, top_p, top_k, temperature, length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
    kwargs = {
        "do_sample": bool(do_sample), "top_p": float(top_p),
        "top_k": int(top_k) if int(top_k) > 0 else None, "temperature": float(temperature),
        "length_penalty": float(length_penalty), "num_beams": num_beams,
        "repetition_penalty": float(repetition_penalty), "max_mel_tokens": int(max_mel_tokens),
    }
    
    try:
        if infer_mode == "æ™®é€šæ¨ç†":
            generated_audio_path = tts.infer(prompt, processed_text, output_audio_path, verbose=cmd_args.verbose,
                                            max_text_tokens_per_sentence=int(max_text_tokens_per_sentence), **kwargs)
        else:
            generated_audio_path = tts.infer_fast(prompt, processed_text, output_audio_path, verbose=cmd_args.verbose,
                                                 max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                                                 sentences_bucket_max_size=(sentences_bucket_max_size), **kwargs)
        
        if generated_audio_path and os.path.exists(generated_audio_path):
            return gr.update(value=generated_audio_path, visible=True)
        else:
            gr.Error("è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼šæ¨¡å‹æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶ã€‚")
            return gr.update(value=None, visible=True)

    except FileNotFoundError as e:
        if prompt and str(e).strip() == prompt.strip():
             gr.Error(f"é”™è¯¯ï¼šå‚è€ƒéŸ³é¢‘æ–‡ä»¶ '{prompt}' æœªæ‰¾åˆ°æˆ–æ— æ³•è®¿é—®ã€‚")
        else:
            gr.Error(f"è¯­éŸ³ç”Ÿæˆæ—¶æ–‡ä»¶æœªæ‰¾åˆ°ï¼š'{str(e)}'ã€‚")
        print(f"FileNotFoundError in gen_single: {e}")
        return gr.update(value=None, visible=True)
    except Exception as e:
        error_msg_user = f"è¯­éŸ³ç”Ÿæˆæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{str(e)}"
        e_str_lower = str(e).lower()
        if "cuda" in e_str_lower and "memory" in e_str_lower:
            error_msg_user = "è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼šæ˜¾å­˜ä¸è¶³ (CUDA out of memory)ã€‚"
        elif "prompt" in e_str_lower or "reference" in e_str_lower or "audio file" in e_str_lower :
            error_msg_user = f"å¤„ç†å‚è€ƒéŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}ã€‚"
        elif "permission denied" in e_str_lower:
            error_msg_user = f"è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼šæƒé™ä¸è¶³ ({str(e)})ã€‚"
        print(f"Unhandled exception in gen_single: {type(e).__name__}: {str(e)}")
        gr.Error(error_msg_user)
        return gr.update(value=None, visible=True)

def update_prompt_audio():
    return gr.update(interactive=True)

# --- Gradio UI å®šä¹‰ ---
with gr.Blocks(title="IndexTTS Demo") as demo:
    mutex = threading.Lock()
    gr.HTML('''
<h2><center>IndexTTS: An Industrial-Level Controllable and Efficient Zero-Shot Text-To-Speech System</h2>
<h2><center>(ä¸€æ¬¾å·¥ä¸šçº§å¯æ§ä¸”é«˜æ•ˆçš„é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿ)</h2>
<p align="center">
<a href='https://arxiv.org/abs/2502.05512'><img src='https://img.shields.io/badge/ArXiv-2502.05512-red'></a>
</p>
    ''')
    with gr.Tab("éŸ³é¢‘ç”Ÿæˆ"):
        with gr.Row():
            prompt_audio = gr.Audio(label="å‚è€ƒéŸ³é¢‘", key="prompt_audio",
                                    sources=["upload", "microphone"], type="filepath")
            with gr.Column():
                input_text_single = gr.TextArea(label="æ–‡æœ¬", key="input_text_single", 
                                               placeholder="è¯·è¾“å…¥ç›®æ ‡æ–‡æœ¬", 
                                               info="å½“å‰æ¨¡å‹ç‰ˆæœ¬{}".format(tts.model_version or "1.0"))
                
                with gr.Accordion("æ‹¼éŸ³/æ–‡æœ¬æ›¿æ¢ç¼–è¾‘å™¨", open=False) as pinyin_editor_accordion:
                    gr.Markdown("""
                    **ä½¿ç”¨è¯´æ˜ï¼š**
                    - **æ ¼å¼ï¼š** `åŸæ–‡:æ›¿æ¢ä¸²,åŸæ–‡:æ›¿æ¢ä¸²,...`
                    - **å•å­—æ‹¼éŸ³ä¿®æ”¹ï¼š** ä¾‹å¦‚ `å¥½:hao3` (æ›¿æ¢ä¸²å¿…é¡»æ˜¯ å­—æ¯+1è‡³4å£°è°ƒ)
                    - **å¤šå­—çŸ­è¯­æ›¿æ¢ï¼š** ä¾‹å¦‚ `æˆ‘åƒçš„:æˆ‘åƒde4` (æ›¿æ¢ä¸²å¯ä»¥æ˜¯æ±‰å­—å’Œæ‹¼éŸ³çš„ç»„åˆ)
                    - å£°è°ƒä»…ç”¨äºå•å­—æ‹¼éŸ³ä¿®æ”¹çš„éªŒè¯ï¼Œæ›¿æ¢ä¸²ä¸­çš„å£°è°ƒç”±ç”¨æˆ·ä¿è¯ã€‚
                    - ä½¿ç”¨è‹±æ–‡é€—å· `,` åˆ†éš”å¤šä¸ªä¿®æ”¹è§„åˆ™ã€‚
                    - **æ³¨æ„ï¼š** è¾ƒé•¿çš„åŸæ–‡åŒ¹é…ä¼šä¼˜å…ˆäºè¾ƒçŸ­çš„åŸæ–‡åŒ¹é…ã€‚
                    """)
                    pinyin_input = gr.TextArea(
                        label="æ‹¼éŸ³/æ–‡æœ¬æ›¿æ¢è§„åˆ™ (è¾“å…¥åä¸‹æ–¹è‡ªåŠ¨é¢„è§ˆ)",
                        placeholder="ä¾‹å¦‚: å§:wo4, æˆ‘åƒçš„:æˆ‘åƒde4, TensorFlow:TensorFlow JS",
                        lines=3, elem_id="pinyin_input_area"
                    )
                    pinyin_preview = gr.TextArea(
                        label="é¢„è§ˆåº”ç”¨æ›¿æ¢åçš„æ–‡æœ¬", interactive=False,
                        lines=3, elem_id="pinyin_preview_area"
                    )
                    gr.Markdown("---")
                    gr.Markdown("**ç®¡ç†æ›¿æ¢è§„åˆ™é›†**")
                    with gr.Row():
                        initial_choices = get_saved_rules_list()
                        # å°è¯•è®¾ç½®ä¸€ä¸ªåˆå§‹å€¼ï¼Œå¦‚æœåˆ—è¡¨ä¸ä¸ºç©º
                        initial_value = initial_choices[0] if initial_choices else None

                        saved_rules_dropdown = gr.Dropdown(
                            label="åŠ è½½å·²ä¿å­˜çš„è§„åˆ™é›†", 
                            choices=get_saved_rules_list(),
                            value=initial_value, # <--- æ·»åŠ æˆ–ä¿®æ”¹è¿™ä¸€è¡Œ
                            interactive=True, scale=2
                        )
                        delete_rules_button = gr.Button("ğŸ—‘ï¸ åˆ é™¤", variant="stop", scale=1)
                    with gr.Row():
                        new_rules_name_input = gr.Textbox(
                            label="å½“å‰è§„åˆ™å¦å­˜ä¸º (è¾“å…¥åç§°)", placeholder="ä¾‹å¦‚ï¼šæˆ‘çš„å¸¸ç”¨è§„åˆ™",
                            scale=2
                        )
                        save_rules_button = gr.Button("ğŸ’¾ ä¿å­˜", variant="primary", scale=1)
                
                infer_mode = gr.Radio(choices=["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"], label="æ¨ç†æ¨¡å¼",
                                     info="æ‰¹æ¬¡æ¨ç†ï¼šæ›´é€‚åˆé•¿å¥ï¼Œæ€§èƒ½ç¿»å€", value="æ™®é€šæ¨ç†")        
                gen_button = gr.Button("ç”Ÿæˆè¯­éŸ³", key="gen_button", interactive=True)
            output_audio = gr.Audio(label="ç”Ÿæˆç»“æœ", visible=True, key="output_audio")
            
        with gr.Accordion("é«˜çº§ç”Ÿæˆå‚æ•°è®¾ç½®", open=False):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("**GPT2 é‡‡æ ·è®¾ç½®**")
                    with gr.Row():
                        do_sample = gr.Checkbox(label="do_sample", value=True, info="æ˜¯å¦è¿›è¡Œé‡‡æ ·")
                        temperature = gr.Slider(label="temperature", minimum=0.1, maximum=2.0, value=1.0, step=0.1)
                    with gr.Row():
                        top_p = gr.Slider(label="top_p", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
                        top_k = gr.Slider(label="top_k", minimum=0, maximum=100, value=30, step=1)
                        num_beams = gr.Slider(label="num_beams", value=3, minimum=1, maximum=10, step=1)
                    with gr.Row():
                        repetition_penalty = gr.Number(label="repetition_penalty", value=10.0, minimum=0.1, maximum=20.0)
                        length_penalty = gr.Number(label="length_penalty", value=0.0, minimum=-2.0, maximum=2.0)
                    max_mel_tokens = gr.Slider(label="max_mel_tokens", value=600, minimum=50, maximum=tts.cfg.gpt.max_mel_tokens, step=10, info="ç”ŸæˆTokenæœ€å¤§æ•°é‡", key="max_mel_tokens")
                with gr.Column(scale=2):
                    gr.Markdown("**åˆ†å¥è®¾ç½®**")
                    with gr.Row():
                        max_text_tokens_per_sentence = gr.Slider(
                            label="åˆ†å¥æœ€å¤§Tokenæ•°", value=120, minimum=20, maximum=tts.cfg.gpt.max_text_tokens, step=2, key="max_text_tokens_per_sentence", info="å»ºè®®80~200"
                        )
                        sentences_bucket_max_size = gr.Slider(
                            label="åˆ†å¥åˆ†æ¡¶æœ€å¤§å®¹é‡(æ‰¹æ¬¡æ¨ç†)", value=4, minimum=1, maximum=16, step=1, key="sentences_bucket_max_size", info="å»ºè®®2-8"
                        )
                    with gr.Accordion("é¢„è§ˆåˆ†å¥ç»“æœ (åŸºäºä¸Šæ–¹æ›¿æ¢è§„åˆ™)", open=True) as sentences_settings:
                        sentences_preview = gr.Dataframe(
                            headers=["åºå·", "åˆ†å¥å†…å®¹", "Tokenæ•°"], key="sentences_preview", wrap=True
                        )
            advanced_params = [
                do_sample, top_p, top_k, temperature,
                length_penalty, num_beams, repetition_penalty, max_mel_tokens,
            ]

        if len(example_cases) > 0:
            gr.Examples(examples=example_cases, inputs=[prompt_audio, input_text_single, infer_mode])

        # --- UI äº‹ä»¶ç›‘å¬ ---
        def on_text_or_pinyin_change_for_sentence_preview(text, pinyin_input_str, max_tokens_per_sentence_val):
            if not text: return {sentences_preview: gr.update(value=[])}
            pinyin_modifications_parsed = parse_pinyin_input(pinyin_input_str)
            valid_modifications_for_splitting = {}
            for key, value in pinyin_modifications_parsed.items():
                if len(key) == 1:
                    if validate_pinyin(value): valid_modifications_for_splitting[key] = value
                else: valid_modifications_for_splitting[key] = value
            processed_text_for_splitting = process_pinyin_text(text, valid_modifications_for_splitting)
            if processed_text_for_splitting and len(processed_text_for_splitting) > 0:
                try:
                    text_tokens_list = tts.tokenizer.tokenize(processed_text_for_splitting)
                    sentences = tts.tokenizer.split_sentences(text_tokens_list, max_tokens_per_sentence=int(max_tokens_per_sentence_val))
                    data = [[i, ''.join(s), len(s)] for i, s in enumerate(sentences)]
                    return {sentences_preview: gr.update(value=data, visible=True)}
                except Exception as e:
                    print(f"Error during sentence splitting preview: {e}")
                    return {sentences_preview: gr.update(value=[["Error", str(e), 0]], visible=True)}
            else: return {sentences_preview: gr.update(value=[])}

        # è§„åˆ™ä¿å­˜ã€åŠ è½½ã€åˆ é™¤çš„äº‹ä»¶å¤„ç†å™¨
        def handle_save_rules(rules_content_str, rules_name_str):
            rules_content_str = rules_content_str if rules_content_str is not None else ""
            success, updated_rules_list, final_rules_name = save_rules_to_file(rules_name_str, rules_content_str)
            if success:
                return {
                    new_rules_name_input: gr.update(value=""), 
                    saved_rules_dropdown: gr.update(choices=updated_rules_list, value=final_rules_name) 
                }
            else:
                return {
                    new_rules_name_input: gr.update(), 
                    saved_rules_dropdown: gr.update(choices=updated_rules_list)
                }

        save_rules_button.click(
            fn=handle_save_rules,
            inputs=[pinyin_input, new_rules_name_input],
            outputs=[new_rules_name_input, saved_rules_dropdown]
        )

        def handle_load_rules_on_dropdown_change(rules_name_str):
            loaded_content = load_rules_from_file(rules_name_str)
            return gr.update(value=loaded_content)

        saved_rules_dropdown.change(
            fn=handle_load_rules_on_dropdown_change,
            inputs=[saved_rules_dropdown],
            outputs=[pinyin_input] 
        )
        
        def handle_delete_rules(rules_name_to_delete):
            if not rules_name_to_delete:
                gr.Warning("è¯·å…ˆä»ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªè§„åˆ™è¿›è¡Œåˆ é™¤ã€‚")
                return gr.update(choices=get_saved_rules_list())

            updated_rules_list = delete_rules_file(rules_name_to_delete)
            return gr.update(choices=updated_rules_list, value=None)

        delete_rules_button.click(
            fn=handle_delete_rules,
            inputs=[saved_rules_dropdown],
            outputs=[saved_rules_dropdown]
        )

        # æ–‡æœ¬/æ‹¼éŸ³è¾“å…¥å˜åŒ–æ—¶æ›´æ–°é¢„è§ˆå’Œåˆ†å¥
        listener_inputs_for_pinyin_preview = [input_text_single, pinyin_input]
        input_text_single.change(fn=preview_pinyin_changes, inputs=listener_inputs_for_pinyin_preview, outputs=[pinyin_preview])
        pinyin_input.change(fn=preview_pinyin_changes, inputs=listener_inputs_for_pinyin_preview, outputs=[pinyin_preview])
        
        listener_inputs_for_sentence_preview = [input_text_single, pinyin_input, max_text_tokens_per_sentence]
        input_text_single.change(fn=on_text_or_pinyin_change_for_sentence_preview, inputs=listener_inputs_for_sentence_preview, outputs=[sentences_preview])
        pinyin_input.change(fn=on_text_or_pinyin_change_for_sentence_preview, inputs=listener_inputs_for_sentence_preview, outputs=[sentences_preview])
        max_text_tokens_per_sentence.change(fn=on_text_or_pinyin_change_for_sentence_preview, inputs=listener_inputs_for_sentence_preview, outputs=[sentences_preview])
        
        # å…¶ä»–æŒ‰é’®äº‹ä»¶
        prompt_audio.upload(update_prompt_audio, inputs=[], outputs=[gen_button])
        gen_button.click(gen_single,
                        inputs=[prompt_audio, input_text_single, pinyin_input, infer_mode,
                               max_text_tokens_per_sentence, sentences_bucket_max_size,
                               *advanced_params],
                        outputs=[output_audio])

# --- å¯åŠ¨ Gradio åº”ç”¨ ---
if __name__ == "__main__":
    demo.queue(max_size=20)
    demo.launch(server_name=cmd_args.host, server_port=cmd_args.port, inbrowser=True)