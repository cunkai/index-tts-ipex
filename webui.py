# FILE: webui.py (Corrected Event Logic and Full Features)
import json
import os
import sys
import threading
import time
import re
import gradio as gr
import torch
import numpy as np

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# --- å…¨å±€è·¯å¾„å’Œé…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

# --- Argument Parsing ---
import argparse
parser = argparse.ArgumentParser(description="IndexTTS ä¸­æ–‡ WebUI")
parser.add_argument("--port", type=int, default=7860, help="Web UI è¿è¡Œç«¯å£")
parser.add_argument("--host", type=str, default="127.0.0.1", help="Web UI è¿è¡Œä¸»æœºåœ°å€")
parser.add_argument("--model_dir", type=str, default="checkpoints", help="æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•")
cmd_args = parser.parse_args()

# --- Model Loading (using the modified IndexTTS class) ---
model_dir_abs = os.path.join(current_dir, cmd_args.model_dir)
try:
    from indextts.infer import IndexTTS
    tts = IndexTTS(model_dir=model_dir_abs, cfg_path=os.path.join(model_dir_abs, "config.yaml"))
    print("æˆåŠŸåŠ è½½ä¿®æ”¹åçš„ IndexTTS å¼•æ“ã€‚")
    DEVICE = tts.device
except Exception as e:
    print(f"è‡´å‘½é”™è¯¯ï¼šæ— æ³•ä» {model_dir_abs} åŠ è½½TTSæ¨¡å‹ã€‚é”™è¯¯: {e}")
    sys.exit(1)

# --- å£°éŸ³ç‰¹å¾æ–‡ä»¶ç®¡ç† ---
SAVED_VOICE_FEATURES_DIR = os.path.join(current_dir, "saved_voice_features")
os.makedirs(SAVED_VOICE_FEATURES_DIR, exist_ok=True)
os.makedirs(os.path.join(current_dir, "outputs"), exist_ok=True)

def sanitize_filename(name):
    return re.sub(r'[^\w\s.-]', '', str(name)).strip()

def get_saved_voices_list():
    if not os.path.exists(SAVED_VOICE_FEATURES_DIR): return []
    return sorted([f.replace(".cond_mel.npy", "") for f in os.listdir(SAVED_VOICE_FEATURES_DIR) if f.endswith(".cond_mel.npy")])

# --- UIè¾…åŠ©å‡½æ•° ---

def save_voice_feature(new_name, mel_to_save):
    if not new_name or not new_name.strip():
        gr.Warning("è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„åç§°æ¥ä¿å­˜å£°éŸ³ç‰¹å¾ã€‚")
        return gr.update()
    if mel_to_save is None:
        gr.Warning("æ²¡æœ‰å¯ä»¥ä¿å­˜çš„æ´»åŠ¨å£°éŸ³ç‰¹å¾ã€‚è¯·å…ˆä»æ–°éŸ³é¢‘ç”Ÿæˆã€‚")
        return gr.update()

    safe_name = sanitize_filename(new_name)
    save_path = os.path.join(SAVED_VOICE_FEATURES_DIR, f"{safe_name}.cond_mel.npy")
    
    try:
        np.save(save_path, mel_to_save.cpu().numpy())
        gr.Info(f"å£°éŸ³ç‰¹å¾ '{safe_name}' å·²æˆåŠŸä¿å­˜ï¼")
        return gr.update(choices=get_saved_voices_list(), value=safe_name)
    except Exception as e:
        gr.Error(f"ä¿å­˜å¤±è´¥: {e}")
        return gr.update()

def delete_voice_feature(voice_name):
    if not voice_name:
        gr.Warning("è¯·å…ˆä»ä¸‹æ‹‰èœå•ä¸­é€‰æ‹©ä¸€ä¸ªè¦åˆ é™¤çš„å£°éŸ³ã€‚")
        return gr.update()

    file_path = os.path.join(SAVED_VOICE_FEATURES_DIR, f"{voice_name}.cond_mel.npy")
    if os.path.exists(file_path):
        try:
            os.remove(file_path)
            gr.Info(f"å£°éŸ³ '{voice_name}' å·²åˆ é™¤ã€‚")
            return gr.update(choices=get_saved_voices_list(), value=None)
        except Exception as e:
            gr.Error(f"åˆ é™¤å¤±è´¥: {e}")
            return gr.update()
    else:
        gr.Warning("æœªæ‰¾åˆ°è¦åˆ é™¤çš„æ–‡ä»¶ã€‚")
        return gr.update(choices=get_saved_voices_list())

def gen_single(uploaded_audio_path, saved_voice_name, text, *args, progress=gr.Progress(track_tqdm=True)):
    prompt_mel = None
    is_from_new_upload = False
    
    # 1. å†³å®šå£°éŸ³æ¥æºå¹¶æå–/åŠ è½½ç‰¹å¾
    if saved_voice_name:
        gr.Info(f"åŠ è½½å·²ä¿å­˜çš„å£°éŸ³: {saved_voice_name}...")
        try:
            mel_path = os.path.join(SAVED_VOICE_FEATURES_DIR, f"{saved_voice_name}.cond_mel.npy")
            prompt_mel = torch.from_numpy(np.load(mel_path)).to(DEVICE)
        except Exception as e:
            gr.Error(f"åŠ è½½å£°éŸ³ç‰¹å¾ '{saved_voice_name}' å¤±è´¥: {e}")
            return None, gr.update(visible=False), None
            
    elif uploaded_audio_path:
        gr.Info(f"ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–å£°éŸ³ç‰¹å¾...")
        try:
            prompt_mel = tts.extract_features(uploaded_audio_path)
            is_from_new_upload = True
        except Exception as e:
            gr.Error(f"ä»éŸ³é¢‘ä¸­æå–ç‰¹å¾å¤±è´¥: {e}")
            return None, gr.update(visible=False), None
    else:
        gr.Warning("é”™è¯¯ï¼šè¯·å…ˆä¸Šä¼ ä¸€ä¸ªæ–°éŸ³é¢‘ï¼Œæˆ–é€‰æ‹©ä¸€ä¸ªå·²ä¿å­˜çš„å£°éŸ³ã€‚")
        return None, gr.update(visible=False), None
        
    # 2. éªŒè¯æ–‡æœ¬è¾“å…¥
    if not text or not text.strip():
        gr.Warning("é”™è¯¯ï¼šæ–‡æœ¬è¾“å…¥ä¸èƒ½ä¸ºç©ºã€‚")
        return None, gr.update(visible=False if not is_from_new_upload else True), prompt_mel if is_from_new_upload else None

    # 3. å‡†å¤‡å‚æ•°å¹¶ç”Ÿæˆ
    output_audio_path = os.path.join(current_dir, "outputs", f"gen_{int(time.time())}.wav")
    do_sample, temp, top_p, top_k, len_penalty, num_beams, rep_penalty, max_new, max_text_per_sent = args
    kwargs = {
        "do_sample": bool(do_sample), "temperature": float(temp), "top_p": float(top_p),
        "top_k": int(top_k) if int(top_k) > 0 else None, "length_penalty": float(len_penalty),
        "num_beams": int(num_beams), "repetition_penalty": float(rep_penalty), "max_new_tokens": int(max_new)
    }

    try:
        gr.Info("è¯­éŸ³ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™...")
        generated_audio_path = tts.infer(
            prompt_mel, text, output_audio_path,
            max_text_tokens_per_sentence=int(max_text_per_sent), **kwargs
        )
        gr.Info("è¯­éŸ³ç”ŸæˆæˆåŠŸï¼")
        
        # 4. æ ¹æ®æ¥æºå†³å®šæ˜¯å¦æ˜¾ç¤ºä¿å­˜æŒ‰é’®
        if is_from_new_upload:
            return gr.update(value=generated_audio_path), gr.update(visible=True), prompt_mel
        else:
            return gr.update(value=generated_audio_path), gr.update(visible=False), None

    except Exception as e:
        gr.Error(f"è¯­éŸ³ç”Ÿæˆæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None, gr.update(visible=False), None

# --- Gradio UI Definition ---
with gr.Blocks(theme=gr.themes.Base(primary_hue=gr.themes.colors.purple, secondary_hue=gr.themes.colors.blue)) as demo:
    newly_extracted_mel_state = gr.State(value=None)
    
    gr.HTML('''<h2 style="text-align: center;">IndexTTS: é›¶æ ·æœ¬è¯­éŸ³åˆæˆç³»ç»Ÿ</h2>''')
    
    with gr.Tab("éŸ³é¢‘ç”Ÿæˆ"):
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### æ­¥éª¤ 1: æä¾›å£°éŸ³æ ·æœ¬")
                prompt_audio = gr.Audio(label="ä¸Šä¼ æ–°éŸ³é¢‘", sources=["upload", "microphone"], type="filepath")
                gr.Markdown("<p style='text-align: center; margin: 5px;'>æˆ–</p>")
                with gr.Row():
                    saved_voices_dropdown = gr.Dropdown(label="é€‰æ‹©å·²ä¿å­˜çš„å£°éŸ³", choices=get_saved_voices_list(), interactive=True)
                    delete_voice_button = gr.Button("ğŸ—‘ï¸", elem_id="delete_button")
                
                with gr.Group(visible=False) as save_voice_group:
                    gr.Markdown("---")
                    gr.Markdown("**ä¿å­˜å½“å‰ç”Ÿæˆçš„å£°éŸ³ç‰¹å¾**")
                    new_voice_name_input = gr.Textbox(label="ä¸ºæ–°å£°éŸ³å‘½å", placeholder="ä¾‹å¦‚ï¼šæ’­éŸ³å‘˜ç”·å£°")
                    save_voice_button = gr.Button("ğŸ’¾ ä¿å­˜å£°éŸ³ç‰¹å¾", variant="secondary")

            with gr.Column(scale=2):
                gr.Markdown("### æ­¥éª¤ 2: è¾“å…¥æ–‡æœ¬å¹¶ç”Ÿæˆ")
                input_text_single = gr.TextArea(label="åˆæˆæ–‡æœ¬", placeholder="åœ¨æ­¤è¾“å…¥æ‚¨æƒ³è¦åˆæˆçš„æ–‡æœ¬...", lines=8)
                gen_button = gr.Button("ç”Ÿæˆè¯­éŸ³", variant="primary")
                output_audio = gr.Audio(label="ç”Ÿæˆç»“æœ", interactive=False)
            
        with gr.Accordion("é«˜çº§ç”Ÿæˆå‚æ•°", open=False):
            # ... (Advanced parameters UI definitions remain the same) ...
            do_sample = gr.Checkbox(label="å¯ç”¨é‡‡æ · (do_sample)", value=True)
            temperature = gr.Slider(label="æ¸©åº¦", minimum=0.1, maximum=2.0, value=1.0, step=0.05)
            top_p = gr.Slider(label="Top-P", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
            top_k = gr.Slider(label="Top-K", minimum=0, maximum=100, value=30, step=1)
            length_penalty = gr.Number(label="é•¿åº¦æƒ©ç½š", value=0.0)
            num_beams = gr.Slider(label="æŸæœç´¢å®½åº¦", value=3, minimum=1, maximum=10, step=1)
            repetition_penalty = gr.Number(label="é‡å¤æƒ©ç½š", value=10.0)
            max_new_tokens = gr.Slider(label="æœ€å¤§ç”ŸæˆTokenæ•°", value=600, minimum=50, maximum=800, step=10)
            max_text_tokens_per_sentence = gr.Slider(label="åˆ†å¥æœ€å¤§Tokenæ•°", value=120, minimum=20, maximum=300, step=2)

        advanced_params = [
            do_sample, temperature, top_p, top_k, length_penalty,
            num_beams, repetition_penalty, max_new_tokens, max_text_tokens_per_sentence
        ]

        # --- CORRECTED UI Event Listeners ---
        
        # When a user MANUALLY SELECTS a voice from the dropdown, clear the audio uploader.
        # .select() is not triggered by programmatic updates, breaking the loop.
        saved_voices_dropdown.select(
            fn=lambda: gr.update(value=None), # Action: clear the audio component
            inputs=None,
            outputs=[prompt_audio]
        )
        
        # When a user UPLOADS or CLEARS the audio, clear the dropdown.
        # .upload() and .clear() are direct user actions.
        prompt_audio.upload(
            fn=lambda: gr.update(value=None), # Action: clear the dropdown
            inputs=None,
            outputs=[saved_voices_dropdown]
        )
        prompt_audio.clear(
            fn=lambda: gr.update(value=None), # Also clear dropdown when 'x' is clicked
            inputs=None,
            outputs=[saved_voices_dropdown]
        )

        # Main generation button
        gen_button.click(
            fn=gen_single,
            inputs=[prompt_audio, saved_voices_dropdown, input_text_single, *advanced_params],
            outputs=[output_audio, save_voice_group, newly_extracted_mel_state]
        )

        # Save and Delete buttons
        save_voice_button.click(fn=save_voice_feature, inputs=[new_voice_name_input, newly_extracted_mel_state], outputs=[saved_voices_dropdown])
        delete_voice_button.click(fn=delete_voice_feature, inputs=[saved_voices_dropdown], outputs=[saved_voices_dropdown])

# --- Launch Gradio App ---
if __name__ == "__main__":
    demo.queue().launch(server_name=cmd_args.host, server_port=cmd_args.port, inbrowser=True)